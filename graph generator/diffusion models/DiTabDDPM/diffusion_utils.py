import torch
import numpy as np
from utils import PlaceHolder
from torch.nn import functional as F


def sum_except_batch(x):

    return x.reshape(x.size(0), -1).sum(dim=-1)

def assert_correctly_masked(variable, node_mask):
    assert (variable * (1 - node_mask.long())).abs().max().item() < 1e-4, \
        'Variables not masked properly.'

def cosine_beta_schedule_discrete(timesteps, s=0.008):
    """ Cosine schedule as proposed in https://openreview.net/forum?id=-NEXDKk8gZ. """
    steps = timesteps + 2
    x = np.linspace(0, steps, steps)

    alphas_cumprod = np.cos(0.5 * np.pi * ((x / steps) + s) / (1 + s)) ** 2
    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]
    alphas = (alphas_cumprod[1:] / alphas_cumprod[:-1])
    betas = 1 - alphas
    return betas.squeeze()

def sample_discrete_features(probF):
    ''' Sample features from multinomial distribution with given probabilities (probX, probE, proby)
        :param probX: bs, n, dx_out        node features
        :param probE: bs, n, n, de_out     edge features
        :param proby: bs, dy_out           global features.
    '''
    bs, n, _ = probF.shape


    # Flatten the probability tensor to sample with multinomial
    probF = probF.reshape(bs * n, -1)       # (bs * n, dx_out)

    # Sample X
    F_t = probF.multinomial(1)                                  # (bs * n, 1)
    F_t = F_t.reshape(bs, n)     # (bs, n)

    return PlaceHolder(Feat=F_t)

def compute_posterior_distribution(M, M_t, Qt_M, Qsb_M, Qtb_M):
    ''' M: X or E
        Compute xt @ Qt.T * x0 @ Qsb / x0 @ Qtb @ xt.T
    '''
    # Flatten feature tensors
    M = M.flatten(start_dim=1, end_dim=-2).to(torch.float32)        # (bs, N, d) with N = n or n * n
    M_t = M_t.flatten(start_dim=1, end_dim=-2).to(torch.float32)    # same

    Qt_M_T = torch.transpose(Qt_M, -2, -1)      # (bs, d, d)

    left_term = M_t @ Qt_M_T   # (bs, N, d)
    right_term = M @ Qsb_M     # (bs, N, d)
    product = left_term * right_term    # (bs, N, d)

    denom = M @ Qtb_M     # (bs, N, d) @ (bs, d, d) = (bs, N, d)
    denom = (denom * M_t).sum(dim=-1)   # (bs, N, d) * (bs, N, d) + sum = (bs, N)
    # denom = product.sum(dim=-1)
    # denom[denom == 0.] = 1

    prob = product / denom.unsqueeze(-1)    # (bs, N, d)

    return prob

def compute_batched_over0_posterior_distribution(Feat_t, Qt, Qsb, Qtb):
    """ M: X or E
        Compute xt @ Qt.T * x0 @ Qsb / x0 @ Qtb @ xt.T for each possible value of x0
        X_t: bs, n, dt          or bs, n, n, dt
        Qt: bs, d_t-1, dt
        Qsb: bs, d0, d_t-1
        Qtb: bs, d0, dt.
    """
    # Flatten feature tensors
    # Careful with this line. It does nothing if X is a node feature. If X is an edge features it maps to
    # bs x (n ** 2) x d
    Feat_t = Feat_t.flatten(start_dim=1, end_dim=-2).to(torch.float32)            # bs x N x dt

    Qt_T = Qt.transpose(-1, -2)                 # bs, dt, d_t-1
    left_term = Feat_t @ Qt_T                      # bs, N, d_t-1
    left_term = left_term.unsqueeze(dim=2)      # bs, N, 1, d_t-1

    right_term = Qsb.unsqueeze(1)               # bs, 1, d0, d_t-1
    numerator = left_term * right_term          # bs, N, d0, d_t-1

    Feat_t_transposed = Feat_t.transpose(-1, -2)      # bs, dt, N

    prod = Qtb @ Feat_t_transposed                 # bs, d0, N
    prod = prod.transpose(-1, -2)               # bs, N, d0
    denominator = prod.unsqueeze(-1)            # bs, N, d0, 1
    denominator[denominator == 0] = 1e-6

    out = numerator / denominator
    return out
def posterior_distributions(Feat, Feat_t, Qt, Qsb, Qtb):
    prob_Feat = compute_posterior_distribution(M=Feat, M_t=Feat_t, Qt_M=Qt.Feat, Qsb_M=Qsb.Feat, Qtb_M=Qtb.Feat)

    return PlaceHolder(Feat=prob_Feat)

def sample_discrete_feature_noise(limit_dist, num_nodes, num_features, num_feature_types):
    """ Sample from the limit distribution of the diffusion process"""

    f_limit = limit_dist.Feat[None, None, :].expand(num_nodes, num_features,-1)

    U_Feat = f_limit.flatten(end_dim=-2).multinomial(1).reshape(num_nodes, num_features)

    U_Feat = F.one_hot(U_Feat, num_classes=f_limit.shape[-1]).float()

    return PlaceHolder(Feat=U_Feat)




