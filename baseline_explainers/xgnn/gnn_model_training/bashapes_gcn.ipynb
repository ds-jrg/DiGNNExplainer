{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a4b40b-629d-4b23-a81c-c86f9b454a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.data import BAShapeDataset\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "359a835c-6839-40cb-91c8-7a70b240c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import easydict\n",
    "import torch_geometric\n",
    "import random\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4556835e-e358-448a-9f6e-5358b752aa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code works in Python 3.10.6\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch_geometric.utils\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets.dblp import DBLP\n",
    "from torch_geometric.nn import GCNConv\n",
    "import time\n",
    "from torch_geometric.logging import log\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d6bbac1-a327-47de-9bde-b92ab62f84fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "dataset = BAShapeDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87e6d5be-c155-4fdc-89dc-e47ce74e22ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ac31239-196e-4f25-b3d9-8aae615580b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=700, num_edges=2055,\n",
       "      ndata_schemes={'feat': Scheme(shape=(1,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
       "      edata_schemes={'__orig__': Scheme(shape=(), dtype=torch.int64)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3c78b76-33b2-4788-aac8-65b7612f9836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = g.ndata['label']\n",
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbcaa90f-29bf-436a-b912-1079e9ed5264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_nodes = g.number_of_nodes()\n",
    "n_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41069705-d36f-4eaa-8e23-e8b6ccd65f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download file BA_shapes.pkl from the dataset in https://github.com/Graph-and-Geometric-Learning/D4Explainer. BA_shapes.pkl is required for the train/val/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90563350-118e-4da6-90eb-32aee3582a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('BA_shapes.pkl', 'rb') as fin:\n",
    "    adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, edge_label_matrix  = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db32b02e-1d10-47fe-8e09-966c6c438338",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.ndata[\"train_mask\"] = torch.tensor(train_mask)\n",
    "g.ndata[\"val_mask\"] = torch.tensor(val_mask)\n",
    "g.ndata[\"test_mask\"] = torch.tensor(test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a74bef9f-93cc-4eb1-86e6-f2fa45d7e857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=700, num_edges=2055,\n",
       "      ndata_schemes={'feat': Scheme(shape=(1,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
       "      edata_schemes={'__orig__': Scheme(shape=(), dtype=torch.int64)})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69039b58-b25e-4a9b-90a1-0834444e3d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 2055], feat=[700, 1], label=[700], train_mask=[700], val_mask=[700], test_mask=[700], __orig__=[2055])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch_geometric.utils.from_dgl(g)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b07b8f5-2447-412d-b5bc-cfe5c85cdf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/4406501/change-the-name-of-a-key-in-dictionary\n",
    "data.x = data.pop('feat')\n",
    "data.y = data.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93327bc2-0ea4-4752-abfd-54a947385353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2008, 1840, 1812,  ..., 1542, 1538, 1543])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.pop('__orig__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbbd08ac-2031-40bd-8862-7de36f2f9054",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0,0.0,0.0,0.0])\n",
    "data.x = x.repeat(data.x.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b071fdb-7a40-4984-b06c-a41078e573e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5af859a2-21ac-41e4-80b4-ebd511f71294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([700, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dbec28c-6533-4e61-9abe-551b67206ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 2055], train_mask=[700], val_mask=[700], test_mask=[700], x=[700, 4], y=[700])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02196b94-4882-4cb7-bdaf-1e6562d160c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = easydict.EasyDict({\n",
    "    \"dataset\": 'BAShapes',\n",
    "    #\"batch_size\": 128,\n",
    "    #\"hidden_channels\": 64,\n",
    "    #\"lr\": 0.0005,\n",
    "    \"epochs\": 2000,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f7b67a5-d5de-47d5-b427-e9e8e2de74f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df272ac6-00bf-4492-98ab-d3a13938744a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving....\n",
      "best acc is 0.14285714285714285\n",
      "saving....\n",
      "best acc is 0.5428571428571428\n",
      "Epoch: 010, Loss: 1.3050, Train: 0.4143, Val: 0.5429, Test: 0.4286\n",
      "Epoch: 020, Loss: 1.2379, Train: 0.4143, Val: 0.5429, Test: 0.4286\n",
      "Epoch: 030, Loss: 1.2111, Train: 0.4143, Val: 0.5429, Test: 0.4286\n",
      "Epoch: 040, Loss: 1.2198, Train: 0.4143, Val: 0.5429, Test: 0.4286\n",
      "Epoch: 050, Loss: 1.2029, Train: 0.4143, Val: 0.5429, Test: 0.4286\n",
      "Epoch: 060, Loss: 1.1347, Train: 0.4143, Val: 0.5429, Test: 0.4286\n",
      "Epoch: 070, Loss: 1.1344, Train: 0.4143, Val: 0.5429, Test: 0.4286\n",
      "Epoch: 080, Loss: 1.1384, Train: 0.4143, Val: 0.5429, Test: 0.4286\n",
      "Epoch: 090, Loss: 1.0370, Train: 0.4143, Val: 0.5429, Test: 0.4286\n",
      "Epoch: 100, Loss: 0.9655, Train: 0.4143, Val: 0.5429, Test: 0.4286\n",
      "Stopping training as validation accuracy did not improve for 100 epochs\n",
      "Median time per epoch: 0.0028s\n"
     ]
    }
   ],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels,\n",
    "                             )\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels,\n",
    "                             )\n",
    "        self.conv3 = GCNConv(hidden_channels, out_channels,\n",
    "                             )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        x = self.conv1(x, edge_index, edge_weight).relu()\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_weight).relu()\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        return x\n",
    "\n",
    "device = 'cpu'\n",
    "model = GCN(\n",
    "    in_channels=data.x.shape[1],\n",
    "    hidden_channels=32,\n",
    "    out_channels=4,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    dict(params=model.conv1.parameters(), weight_decay=5e-4),\n",
    "    dict(params=model.conv2.parameters(), weight_decay=0),\n",
    "    dict(params=model.conv3.parameters(), weight_decay=0)\n",
    "], lr=0.01)  # Only perform weight-decay on first convolution.\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    pred = model(data.x, data.edge_index).argmax(dim=-1)\n",
    "\n",
    "    accs = []\n",
    "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
    "        accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
    "    return accs\n",
    "\n",
    "\n",
    "best_val_acc = test_acc = 0\n",
    "start_patience = patience = 100\n",
    "times = []\n",
    "for epoch in range(1, 2000 + 1):\n",
    "    start = time.time()\n",
    "    loss = train()\n",
    "    train_acc, val_acc, tmp_test_acc = test()\n",
    "    if val_acc > best_val_acc:\n",
    "        test_acc = tmp_test_acc\n",
    "    if epoch%10==0:\n",
    "        log(Epoch=epoch, Loss=loss, Train=train_acc, Val=val_acc, Test=test_acc)\n",
    "    times.append(time.time() - start)\n",
    "\n",
    "    if (val_acc>best_val_acc):\n",
    "        print('saving....')\n",
    "        patience = start_patience\n",
    "        best_val_acc = val_acc\n",
    "        print('best acc is', best_val_acc)\n",
    "\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(model.state_dict(), '../checkpoint/BA_shapes_gcn.pth')\n",
    "    else:\n",
    "        patience -= 1\n",
    "        \n",
    "    if patience <= 0:\n",
    "        print('Stopping training as validation accuracy did not improve '\n",
    "              f'for {start_patience} epochs')\n",
    "        break   \n",
    "        \n",
    "print(f'Median time per epoch: {torch.tensor(times).median():.4f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e2cf95-208e-464d-9fee-5963a044cf03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657fe3af-f0b6-4e65-982b-9e5d64e6cc29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
